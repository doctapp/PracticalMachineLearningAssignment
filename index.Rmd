---
title: "Exercise Manner Prediction"
author: "Martin Tapp"
date: "March 25, 2016"
output: html_document
---

### Summary

We present a model which predicts how well people practice barbell lifts based on wearable data. The results were derived from the Human Activity Recognition (HAR) data which is available at http://groupware.les.inf.puc-rio.br/har. The full data processing is provided for anyone wishing to reproduce these results.


### Exploratory Data Analysis

Looking at the data reveals many missing values which we remove from the training and testing datasets. Moreover, the first seven columns of the dataset are considered irrelevent to the prediction of exercise manner as they reffer to data such as user name and timestamps. We started with 160 features including `classe`, the outcome to predict, and are now left with 53 features to work with.

```{r, results='hide', warning=FALSE, message=FALSE}
read_csv <- function(path) {
    raw <- read.csv(path, header=TRUE, na.strings=c('NA', ''),
                    colClasses=c(rep('NULL', 7), rep(NA, 160-7)))
    raw[,colSums(is.na(raw))==0]
}
raw_train <- read_csv('pml-training.csv')
raw_test  <- read_csv('pml-testing.csv')
```

The model we build is used to predict the `classe` outcome. Note that we will use our model against the testing dataset to predict how users performed.

### Model Building

Before building our model, we start by creating training and testing sets from the raw training dataset. The training set is used to train our model while the testing set is used to validate it. We also set the random seed for reproducability.

```{r, results='hide', warning=FALSE, message=FALSE}
library(caret)
library(randomForest)
set.seed(32744)
inTrain <- createDataPartition(raw_train$classe, p=0.8, list=F)
training <- raw_train[inTrain,]
testing  <- raw_train[-inTrain,]
```

Next, we build a model to predict `classe` which represents how a person fared against a specific exercise. We fit our model using all the features we selected in our exploratory data analysis. The fist model uses Random Forest. We determine the model's accuracy by predicting against the testing set and looking at the confusion matrix.

```{r, results='hide', warning=FALSE, message=FALSE}
model_rf <- randomForest(classe ~ ., data=training)
pred_rf <- predict(model_rf, testing)
cm_rf <- confusionMatrix(testing$classe, pred_rf)
accuracy_rf <- round(cm_rf$overall[[1]] * 100, 2)
```

We can see that the model performed well against each `classe` yielding a 99.62% accuracy. Looking at the confusion matrix shows where the model is stronger (perfect for `A`) and weaker (5 mismatches for `B` and `D`).

```{r}
cm_rf$table
```

Next, we compare the Random Forest model to a Linear Discriminant Analysis (LDA) model and a Boosting model.

```{r, results='hide', warning=FALSE, message=FALSE}
model_lda <- train(classe ~ ., data=training, method="lda", verbose = FALSE)
pred_lda <- predict(model_lda, testing)
cm_lda <- confusionMatrix(testing$classe, pred_lda)
accuracy_lda <- round(cm_lda$overall[[1]] * 100, 2)

tc <- trainControl(allowParallel=T, method="cv", number=2)
model_gbm <- train(classe ~ ., data=training, method="gbm", verbose = FALSE, trControl=tc)
pred_gbm <- predict(model_gbm, testing)
cm_gbm <- confusionMatrix(testing$classe, pred_gbm)
accuracy_gbm <- round(cm_gbm$overall[[1]] * 100, 2)
```

The LDA model fairs poorly with an accuracy of 68.93% while Boosting gets close to Random Forest with 96.18%. Therefore, we will be using the Random Forest for predicting `classe`.

### Predictions

Finally, we predict `classe` for the original testing dataset using the Random Forest model which yields the following predictions.

```{r}
predict(model_rf, raw_test)
```

### Insights

We presented a model for predicting how people fare in exercises based on data gathered using wearable devices. Finally, we saw that Random Forest provided the best accuracy compared to the other models used.